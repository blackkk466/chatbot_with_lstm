{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackkk466/chatbot_with_lstm/blob/master/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jRqU8IMdPz8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "cd5f2149-d97e-4415-ae2b-454f6663728a"
      },
      "cell_type": "code",
      "source": [
        "!pip install tflearn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/ec/e9ce1b52e71f6dff3bd944f020cef7140779e783ab27512ea7c7275ddee5/tflearn-0.3.2.tar.gz (98kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.11.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->tflearn) (0.46)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Running setup.py bdist_wheel for tflearn ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d0/f6/69/0ef3ee395aac2e5d15d89efd29a9a216f3c27767b43b72c006\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "81vv6jp3JqaF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import six\n",
        "from six.moves import urllib\n",
        "\n",
        "import tflearn\n",
        "from tflearn.data_utils import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wkjrrz3AKag2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a71bf604-c000-422d-d7d1-910a5dd9f831"
      },
      "cell_type": "code",
      "source": [
        "path = \"S1B1.txt\"\n",
        "char_idx_file = 'char_idx.pickle'\n",
        "maxlen = 100\n",
        "char_idx = None\n",
        "\n",
        "X, Y, char_idx = textfile_to_semi_redundant_sequences(path, seq_maxlen=maxlen, redun_step=3,\n",
        "                                                     pre_defined_char_idx=char_idx)\n",
        "\n",
        "pickle.dump(char_idx, open(char_idx_file, 'wb'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorizing text...\n",
            "Text total length: 32,438\n",
            "Distinct chars   : 83\n",
            "Total sequences  : 10,780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PSsWKF3PM-kT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "30590018-7339-44fb-eb8b-f5d46081fe66"
      },
      "cell_type": "code",
      "source": [
        "q = tflearn.input_data([None, maxlen, len(char_idx)])\n",
        "q = tflearn.lstm(q, 128, return_seq=True)\n",
        "q = tflearn.dropout(q, 0.5)\n",
        "q = tflearn.lstm(q, 128, return_seq=True)\n",
        "q = tflearn.dropout(q, 0.5)\n",
        "q = tflearn.lstm(q, 128)\n",
        "q = tflearn.dropout(q, 0.5)\n",
        "\n",
        "q = tflearn.fully_connected(q, len(char_idx), activation='softmax')\n",
        "q = tflearn.regression(q, optimizer='adam', loss='categorical_crossentropy', learning_rate=0.001)\n",
        "\n",
        "m = tflearn.SequenceGenerator(q, dictionary=char_idx, seq_maxlen=maxlen,\n",
        "                             clip_gradients=5.0, checkpoint_path='model_mentalist')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "byTXu1BRNZqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1326
        },
        "outputId": "fe2cd0b0-a832-4f37-d420-8bd699cea587"
      },
      "cell_type": "code",
      "source": [
        "for i in range(50):\n",
        "  seed = random_sequence_from_textfile(path, maxlen)\n",
        "  m.fit(X, Y, validation_set=0.1, batch_size=128, n_epoch=1, run_id='mentalist')\n",
        "  print(\"--TESTING...\")\n",
        "  print(\"--Test with temperature of 1.0 ---\")\n",
        "  print(m.generate(600, temperature=1.0, seq_seed=seed))\n",
        "  print(\"--TESTING...\")\n",
        "  print(\"--Test with temperature of 0.5 ---\")\n",
        "  print(m.generate(600, temperature=0.5, seq_seed=seed))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 3875  | total loss: \u001b[1m\u001b[32m1.95129\u001b[0m\u001b[0m | time: 15.032s\n",
            "| Adam | epoch: 051 | loss: 1.95129 -- iter: 9600/9702\n",
            "Training Step: 3876  | total loss: \u001b[1m\u001b[32m1.96093\u001b[0m\u001b[0m | time: 16.594s\n",
            "| Adam | epoch: 051 | loss: 1.96093 | val_loss: 1.91378 -- iter: 9702/9702\n",
            "--\n",
            "INFO:tensorflow:/content/model_mentalist-3876 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "WARNING:tensorflow:Issue encountered when serializing layer_tensor/LSTM.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'list' object has no attribute 'name'\n",
            "WARNING:tensorflow:Issue encountered when serializing layer_tensor/Dropout.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'list' object has no attribute 'name'\n",
            "WARNING:tensorflow:Issue encountered when serializing layer_tensor/LSTM_1.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'list' object has no attribute 'name'\n",
            "--TESTING...\n",
            "--Test with temperature of 1.0 ---\n",
            "iniz yok.]\n",
            "\n",
            "[00023][Juniper][İnanın.]\n",
            "\n",
            "[00024][Jane][İnanıyorum.]\n",
            "\n",
            "[00025][Jane][Biliyorum.]\n",
            "\n",
            "[00026][Wagyereeuye koncek Peidene.][Se oslüyısmımuyumun nacebiraz rakıdlın?]\n",
            "\n",
            "[00693][Van Püçeayene setden Poitop  beter?]\n",
            "\n",
            "[00501][Janir][Oy?]\n",
            "\n",
            "[00485][Mrlere geğan,ezondalin de,ltindenrirsanel Jen.]\n",
            "\n",
            "[00r40][Sogurd][suğtısı,tzen, nazuğiy.]\n",
            "\n",
            "[00228][Ragte osmen keptin Pınta eğerin bep Jon Aauyaluşüy.]\n",
            "\n",
            "[00239][Janir][Bel re gaıbira çenı beğ.]\n",
            "\n",
            "[0035o][Put 1lenagi bağüriakir Poka mes.]\n",
            "\n",
            "[00697][Polanturdanır tünulügangenimaizener'e Jemin Jon Ra?enei be alşr.]\n",
            "\n",
            "[00055][Cne][Asılisam.]\n",
            "\n",
            "[00442][LuçJin][Jahur ğet?]\n",
            "\n",
            "[00465][Lomgan][İgına.]\n",
            "\n",
            "[00544][Ja 6iner][Onya büriyı, ba?]\n",
            "\n",
            "[00060][Presinel Pen Den\n",
            "--TESTING...\n",
            "--Test with temperature of 0.5 ---\n",
            "iniz yok.]\n",
            "\n",
            "[00023][Juniper][İnanın.]\n",
            "\n",
            "[00024][Jane][İnanıyorum.]\n",
            "\n",
            "[00025][Jane][Biliyorum.]\n",
            "\n",
            "[00026][Pinter][Si?]\n",
            "\n",
            "[00651][Jane][Ser derıran yar şaltadıyeye demi beye var kazdan kar nazan benimılıyin koklırız kontık gedirıni gamişdırar kez ber ben her saram sana kaşırlerin  burler ber saca dapılirazi kacıyirun za?]\n",
            "\n",
            "[00506][Raginter Paseenen Pelterin senden Pelden.]\n",
            "\n",
            "[00005][Jane][Ser anı bilir ilimırı ban saşiyı çer barum kinun.]\n",
            "\n",
            "[00046][Jane][Her gon lekle dayirarkadir ba ollarümın mikdanır.]\n",
            "\n",
            "[00540][Jane][Nelin yoyle anıli sarun kar sarün ba den gerdının bir niyo iltiyir.]\n",
            "\n",
            "[00314][Pilter Pelmeyıyen Per ser sen sazter Raknaber adar ilir danın karlarde.]\n",
            "\n",
            "[00225][Wanner][Karleğin yaru ş\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}