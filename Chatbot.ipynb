{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackkk466/chatbot_with_lstm/blob/master/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jRqU8IMdPz8y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tflearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "81vv6jp3JqaF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import six\n",
        "from six.moves import urllib\n",
        "\n",
        "import tflearn\n",
        "from tflearn.data_utils import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wkjrrz3AKag2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = \"S1B1.txt\"\n",
        "char_idx_file = 'char_idx.pickle'\n",
        "maxlen = 100\n",
        "char_idx = None\n",
        "\n",
        "X, Y, char_idx = textfile_to_semi_redundant_sequences(path, seq_maxlen=maxlen, redun_step=3, pre_defined_char_idx=char_idx)\n",
        "\n",
        "pickle.dump(char_idx, open(char_idx_file, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PSsWKF3PM-kT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "q = tflearn.input_data([None, maxlen, len(char_idx)])\n",
        "q = tflearn.lstm(q, 128, return_seq=True)\n",
        "q = tflearn.dropout(q, 0.5)\n",
        "q = tflearn.lstm(q, 128, return_seq=True)\n",
        "q = tflearn.dropout(q, 0.5)\n",
        "q = tflearn.lstm(q, 128)\n",
        "q = tflearn.dropout(q, 0.5)\n",
        "\n",
        "q = tflearn.fully_connected(q, len(char_idx), activation='softmax')\n",
        "q = tflearn.regression(q, optimizer='adam', loss='categorical_crossentropy', learning_rate=0.001)\n",
        "\n",
        "m = tflearn.SequenceGenerator(q, dictionary=char_idx, seq_maxlen=maxlen, clip_gradients=5.0, checkpoint_path='model_mentalist')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "byTXu1BRNZqk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(50):\n",
        "  seed = random_sequence_from_textfile(path, maxlen)\n",
        "  m.fit(X, Y, validation_set=0.1, batch_size=128, n_epoch=1, run_id='mentalist'),\n",
        "  print(\"--TESTING...\")\n",
        "  print(\"--Test with temperature of 0.5 ---\")\n",
        "  print(m.generate(600, temperature=0.5, seq_seed=seed))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}